{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNMLM/jFq+wVkS3cCAW/88i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amrit-Raj-17/GenAI/blob/main/NLP_Assignment2_AmritRajThakur.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NAME : AMRIT RAJ THAKUR\n",
        "# SEC : A\n",
        "# ROLL NO. : 38\n",
        "# ENROLL NO. : 12022002002062"
      ],
      "metadata": {
        "id": "DUxf22KJH-XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvEFXfTIHHCo",
        "outputId": "ab56bc98-9e78-4a5e-944f-59bced1342b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1 : Load and Test a Pre-Trained NLP Model\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load a text generation model (e.g., GPT-2)\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# Define a prompt\n",
        "prompt = \"The future of AI is\"\n",
        "\n",
        "# Generate text\n",
        "generated_text = generator(prompt, max_length=50)\n",
        "\n",
        "# Print generated text\n",
        "print(\"Generated Text:\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cggsHIS1HLeL",
        "outputId": "e71b4fd7-2b05-4ba5-e42b-1f4e5039a56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "[{'generated_text': \"The future of AI is uncertain. If there's an opportunity for future AI to solve our problems better, it needs to be smart. And if we still have humans, that's a nice and simple choice. The AI industry is well on its way\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "\n",
        "When using a prompt such as \"The future of AI is\", the model (GPT-2 in this case) generates a continuation that reflects its training data.\n",
        "\n",
        "Adjusting the prompt (for example, adding more context or changing the tone) can significantly affect the output. A more detailed prompt can guide the model toward a more specific narrative or style.\n",
        "\n",
        "**Explanations:**\n",
        "\n",
        "Model Behavior: GPT-2 uses a transformer-based architecture to predict the next word in a sequence. The text generation is probabilistic, meaning that even small changes in the prompt or parameters (like max_length) may lead to different outputs each time.\n",
        "\n",
        "Prompt Engineering: Experimenting with various prompts is key. A well-crafted prompt provides clear guidance to the model, often resulting in more relevant and focused output.\n",
        "\n",
        "Output Analysis: Look at aspects such as coherence, logical flow, and creativity. For instance, if the output seems too generic or off-topic, consider refining your prompt."
      ],
      "metadata": {
        "id": "D94ZjBnuJFJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2 : Sentiment Analysis using a Pre-Trained Model\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the sentiment analysis pipeline\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Define test sentences\n",
        "texts = [\"I love using Hugging Face!\", \"This assignment is difficult.\"]\n",
        "\n",
        "# Perform sentiment analysis\n",
        "results = sentiment_pipeline(texts)\n",
        "\n",
        "# Display results\n",
        "for text, result in zip(texts, results):\n",
        "    print(f\"Text: {text}\\nSentiment: {result['label']} (Score: {result['score']:.4f})\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSzDumPGHW-h",
        "outputId": "27b8b575-206e-4c97-c412-4b831928b191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I love using Hugging Face!\n",
            "Sentiment: POSITIVE (Score: 0.9997)\n",
            "\n",
            "Text: This assignment is difficult.\n",
            "Sentiment: NEGATIVE (Score: 0.9987)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "\n",
        "The pipeline correctly identified positive sentiment in texts such as \"I love using Hugging Face!\" and negative sentiment in statements like \"This assignment is difficult.\"\n",
        "\n",
        "Each sentiment output includes a confidence score, indicating the model’s certainty. Typically, high confidence (e.g., scores close to 1.0) suggests that the model is sure about its classification.\n",
        "\n",
        "**Explanations:**\n",
        "\n",
        "Model Functionality: The sentiment analysis pipeline leverages pre-trained models (often fine-tuned on large sentiment datasets) that can classify text into categories like positive, negative, or sometimes neutral.\n",
        "\n",
        "Confidence Scores: These scores help you understand the reliability of the prediction. A high score means the model is confident, whereas lower scores might indicate ambiguous sentiment or mixed emotions in the text.\n",
        "\n",
        "Testing on Varied Sentences: By expanding your tests to include more diverse sentences (e.g., those with sarcasm, mixed feelings, or complex language), you can better evaluate the robustness of the model and observe any misclassifications.\n"
      ],
      "metadata": {
        "id": "vcljt6NaJrf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3 : Named Entity Recognition (NER)\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the NER pipeline\n",
        "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
        "\n",
        "# Sample text for NER\n",
        "text = \"Hugging Face was founded in New York by Clement Delangue.\"\n",
        "\n",
        "# Perform NER\n",
        "entities = ner_pipeline(text)\n",
        "\n",
        "# Display results\n",
        "for entity in entities:\n",
        "    print(f\"Entity: {entity['word']}, Label: {entity['entity']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwGto8YfHcwX",
        "outputId": "1fb15d4b-1152-4a6e-b99e-bf769be4624d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: Hu, Label: I-ORG\n",
            "Entity: ##gging, Label: I-ORG\n",
            "Entity: Face, Label: I-ORG\n",
            "Entity: New, Label: I-LOC\n",
            "Entity: York, Label: I-LOC\n",
            "Entity: Clement, Label: I-PER\n",
            "Entity: Del, Label: I-PER\n",
            "Entity: ##ang, Label: I-PER\n",
            "Entity: ##ue, Label: I-PER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "\n",
        "When processing a sample sentence like \"Hugging Face was founded in New York by Clement Delangue.\", the NER pipeline successfully identified key entities:\n",
        "\n",
        "Organization: “Hugging Face”\n",
        "\n",
        "Location: “New York”\n",
        "\n",
        "Person: “Clement Delangue”\n",
        "\n",
        "Sometimes the output might include subword tokens if the model splits unknown words. This can occur due to the tokenizer’s handling of certain terms.\n",
        "\n",
        "**Explanations:**\n",
        "\n",
        "NER Model: The chosen model (e.g., dbmdz/bert-large-cased-finetuned-conll03-english) is fine-tuned on datasets like CoNLL-2003, making it effective in recognizing common entity types (persons, organizations, locations, etc.).\n",
        "\n",
        "Entity Boundaries: The model uses token-level classification to determine where entities start and end. Occasional subword splits or misclassifications can be addressed by post-processing the outputs if needed.\n",
        "\n",
        "Practical Use: NER can be particularly useful for extracting structured information from unstructured texts, such as news articles or Wikipedia entries, which you can further analyze for trends or insights.\n"
      ],
      "metadata": {
        "id": "RaS1kYo7J5jz"
      }
    }
  ]
}